{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Learning via ML\n",
    "\n",
    "1. Bag Of Words\n",
    "2. StopWords\n",
    "3. Stemming\n",
    "4. NLTK\n",
    "5. TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words\n",
    "\n",
    "Bag of Words is like tossing all the words we encounter as individual tokens with their frequency of occurance in input. If the word happens to repeat we will have only one instance of it with tied frequency on how many times it has been repeated.\n",
    "\n",
    "** Note: Loves and Love are not same, advance tooling to be studied later will help cover such issues **\n",
    "![ML](images/ml62.png)\n",
    "\n",
    "** Note: 'Chicago Bulls' is sports team, but at this stage system can't contextually understand this, will treat this as separate words, advance tooling to be studied later will help cover such issues **\n",
    "\n",
    "![ML](images/ml61.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's implement BagOfWords with sklearn\n",
    "\n",
    "** In sklearn Bag Of Words is referred as CountVectorizer as it doing nothing counting word frequencies **\n",
    "\n",
    "http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x9 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 19 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "corpus = [\n",
    "     'This is the first document.',\n",
    "     'This is the second second document.',\n",
    "     'And the third one.',\n",
    "     'Is this the first document?']\n",
    "\n",
    "# Fit words from corpus, which means convert them to indices\n",
    "bag_of_words = vectorizer.fit(corpus)\n",
    "\n",
    "# Transform count the words frequency, keep one instance with with count\n",
    "bag_of_words = vectorizer.transform(corpus)\n",
    "\n",
    "## *** Alternative above two steps can be done in one as : vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: (0,1) stands for 0th document (first document) & 1st word, ...\n",
      " which is nothing by ''this'', followed by occurence count in that document ...\n",
      "\n",
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 8)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 5)\t2\n",
      "  (1, 6)\t1\n",
      "  (1, 8)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 7)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 3)\t1\n",
      "  (3, 6)\t1\n",
      "  (3, 8)\t1\n"
     ]
    }
   ],
   "source": [
    "print \"Example: (0,1) stands for 0th document (first document) & 1st word, ...\"\n",
    "print \" which is nothing by ''this'', followed by occurence count in that document ...\"\n",
    "print(\"\")\n",
    "print bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'and',\n",
       " u'document',\n",
       " u'first',\n",
       " u'is',\n",
       " u'one',\n",
       " u'second',\n",
       " u'the',\n",
       " u'third',\n",
       " u'this']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'and': 0,\n",
       " u'document': 1,\n",
       " u'first': 2,\n",
       " u'is': 3,\n",
       " u'one': 4,\n",
       " u'second': 5,\n",
       " u'the': 6,\n",
       " u'third': 7,\n",
       " u'this': 8}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WE HAVE FEATURE LIST OR VOCABULARY OF 9 WORDS AS LISTED ABOVE ...\n",
      "IT IS SORTED IN ALPHABETICAL ORDER ...\n",
      "THE ARRAY VALUES BELOW SHOWS 0 OR 1 IF WORD FOUND IN DOCUMENT AT VOCAB INDEX ...\n",
      "HENCE THE ARRAY LEGTH AS 9 ...\n",
      "\n",
      "This is the first document.\n",
      "[0 1 1 1 0 0 1 0 1]\n",
      "\n",
      "This is the second second document.\n",
      "[0 1 0 1 0 2 1 0 1]\n",
      "\n",
      "And the third one.\n",
      "[1 0 0 0 1 0 1 1 0]\n",
      "\n",
      "Is this the first document?\n",
      "[0 1 1 1 0 0 1 0 1]\n",
      "\n",
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 1 0 1 0 2 1 0 1]\n",
      " [1 0 0 0 1 0 1 1 0]\n",
      " [0 1 1 1 0 0 1 0 1]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"WE HAVE FEATURE LIST OR VOCABULARY OF 9 WORDS AS LISTED ABOVE ...\"\n",
    "print \"IT IS SORTED IN ALPHABETICAL ORDER ...\"\n",
    "print \"THE ARRAY VALUES BELOW SHOWS 0 OR 1 IF WORD FOUND IN DOCUMENT AT VOCAB INDEX ...\"\n",
    "print \"HENCE THE ARRAY LEGTH AS 9 ...\\n\"\n",
    "\n",
    "print 'This is the first document.'\n",
    "print  bag_of_words.toarray()[0]\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print 'This is the second second document.'\n",
    "print  bag_of_words.toarray()[1]\n",
    "print(\"\")\n",
    "\n",
    "print 'And the third one.'\n",
    "print  bag_of_words.toarray()[2]\n",
    "print(\"\")\n",
    "\n",
    "print 'Is this the first document?'\n",
    "print  bag_of_words.toarray()[3]\n",
    "print(\"\")\n",
    "\n",
    "print  bag_of_words.toarray()\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_.get(\"third\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
